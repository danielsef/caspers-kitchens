{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Complaint Agent Stream\n",
    "\n",
    "This notebook streams complaints through the complaint agent for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().getOrElse(None)\n",
    "DATABRICKS_HOST = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().getOrElse(None)\n",
    "\n",
    "CATALOG = dbutils.widgets.get(\"CATALOG\")\n",
    "COMPLAINT_AGENT_ENDPOINT_NAME = dbutils.widgets.get(\"COMPLAINT_AGENT_ENDPOINT_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pyspark.sql import functions as F\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.functions import udf\nimport json\n\nfrom openai import OpenAI\n\ndef process_complaint(complaint_text: str, order_id: str) -> str:\n    \"\"\"Process a complaint through the agent endpoint.\"\"\"\n    client = OpenAI(\n        api_key=DATABRICKS_TOKEN,\n        base_url=f\"{DATABRICKS_HOST}/serving-endpoints\",\n    )\n    \n    default_response = json.dumps({\n        \"order_id\": order_id,\n        \"complaint_category\": \"other\",\n        \"decision\": \"escalate\",\n        \"credit_amount\": 0.0,\n        \"rationale\": \"agent did not return valid JSON\",\n        \"customer_response\": \"We're reviewing your complaint and will get back to you shortly.\"\n    })\n    \n    for _ in range(3):\n        try:\n            # Call agent endpoint\n            chat_completion = client.chat.completions.create(\n                model=f\"{COMPLAINT_AGENT_ENDPOINT_NAME}\",\n                messages=[{\n                    \"role\": \"user\", \n                    \"content\": f\"{complaint_text} (Order ID: {order_id})\"\n                }],\n            )\n            response = chat_completion.messages[-1].get(\"content\")\n            \n            # Validate JSON\n            json.loads(response)\n            return response\n        except Exception as e:\n            # If call fails, continue to retry\n            continue\n    \n    # After 3 retries, return default response\n    return default_response\n\nprocess_complaint_udf = udf(process_complaint, StringType())"
  },
  {
   "cell_type": "code",
   "source": "# Stream processing\ncomplaint_responses = (\n    spark.readStream\n    .table(f\"{CATALOG}.complaints.raw_complaints\")\n    .select(\n        F.col(\"complaint_id\"),\n        F.col(\"order_id\"),\n        F.current_timestamp().alias(\"ts\"),\n        process_complaint_udf(F.col(\"complaint_text\"), F.col(\"order_id\")).alias(\"agent_response\")\n    )\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS ${CATALOG}.complaints;\n",
    "CREATE VOLUME IF NOT EXISTS ${CATALOG}.complaints.checkpoints;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS ${CATALOG}.complaints.complaint_responses (\n",
    "  complaint_id STRING,\n",
    "  order_id STRING,\n",
    "  ts TIMESTAMP,\n",
    "  agent_response STRING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Enable Change Data Feed for Lakebase sync\n",
    "ALTER TABLE ${CATALOG}.complaints.complaint_responses \n",
    "SET TBLPROPERTIES (delta.enableChangeDataFeed = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaint_responses.writeStream \\\n",
    "    .option(\"checkpointLocation\", f\"/Volumes/{CATALOG}/complaints/checkpoints/complaint_agent_stream\") \\\n",
    "    .trigger(availableNow=True) \\\n",
    "    .table(f\"{CATALOG}.complaints.complaint_responses\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}