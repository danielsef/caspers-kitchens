{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = dbutils.widgets.get(\"CATALOG\")\n",
    "COMPLAINT_LAKEBASE_INSTANCE_NAME = f\"{CATALOG}complaintmanager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install databricks-sdk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.database import DatabaseInstance\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from uc_state import add\n",
    "\n",
    "# Initialize the Workspace client\n",
    "w = WorkspaceClient()\n",
    "\n",
    "UNIQUE = str(uuid.uuid4())[:8]\n",
    "\n",
    "# Create a database instance\n",
    "instance = w.database.create_database_instance(\n",
    "    DatabaseInstance(\n",
    "        name=f\"{COMPLAINT_LAKEBASE_INSTANCE_NAME}\",\n",
    "        capacity=\"CU_1\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Created database instance: {instance.name}\")\n",
    "add(CATALOG, \"databaseinstances\", {\"name\": instance.name, \"type\": \"complaint\"})\n",
    "print(f\"Connection endpoint: {instance.response.read_write_dns}\")\n",
    "\n",
    "# block until it's actually ready\n",
    "print(\"Waiting for database instance to be available...\")\n",
    "while True:\n",
    "    if str(w.database.get_database_instance(instance.name).state) == \"DatabaseInstanceState.AVAILABLE\":\n",
    "        print(str(w.database.get_database_instance(instance.name).state))\n",
    "        break\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database `caspers_complaints` in the lakebase instance\n",
    "# register it to UC as concat of CATALOG-INSTANCE_NAME (params)\n",
    "\n",
    "from databricks.sdk.service.database import DatabaseCatalog\n",
    "\n",
    "catalog = w.database.create_database_catalog(\n",
    "    DatabaseCatalog(\n",
    "        name=f\"{COMPLAINT_LAKEBASE_INSTANCE_NAME}\",                   # Name of the UC catalog to create\n",
    "        database_instance_name=COMPLAINT_LAKEBASE_INSTANCE_NAME, # Name of the database instance\n",
    "        database_name=\"caspers_complaints\",         # Name of the Postgres database to register (and optionally create)\n",
    "        create_database_if_not_exists=True    # Create the database if it doesn't exist\n",
    "    )\n",
    ")\n",
    "print(f\"Created new database and catalog: {catalog.name}\")\n",
    "\n",
    "add(CATALOG, \"databasecatalogs\", catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.database import SyncedDatabaseTable, SyncedTableSpec, NewPipelineSpec, SyncedTableSchedulingPolicy\n",
    "\n",
    "# Initialize the Workspace client\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Create a synced table in a standard UC catalog\n",
    "synced_table = w.database.create_synced_database_table(\n",
    "    SyncedDatabaseTable(\n",
    "        name=f\"{CATALOG}.complaints.pg_complaint_responses\",  # Full three-part name\n",
    "        database_instance_name=instance.name,  # Required for standard catalogs\n",
    "        logical_database_name=\"caspers_complaints\",  # Required for standard catalogs\n",
    "        spec=SyncedTableSpec(\n",
    "            source_table_full_name=f\"{CATALOG}.complaints.complaint_responses\",\n",
    "            primary_key_columns=[\"complaint_id\"],\n",
    "            scheduling_policy=SyncedTableSchedulingPolicy.CONTINUOUS,\n",
    "            create_database_objects_if_missing=True,  # Create database/schema if needed\n",
    "            new_pipeline_spec=NewPipelineSpec(\n",
    "                storage_catalog=\"storage_catalog\",\n",
    "                storage_schema=\"storage_schema\"\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "print(f\"Created synced table: {synced_table.name}\")\n",
    "add(CATALOG, \"pipelines\", synced_table.data_synchronization_status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
