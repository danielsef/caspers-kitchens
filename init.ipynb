{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddd5b0fd-469c-4eb8-b467-64c128596d15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Casper's Ghost Kitchen Initializer\n",
    "\n",
    "Select `Run All` to initialize Casper's Databricks environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45bf8d75-b68f-4025-95df-41b9909f2361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade databricks-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19fe1502-c847-4132-9149-46635a242995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dc89f3e-7fa9-45c0-b173-e6e8a7ad0885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CATALOG = dbutils.widgets.get(\"CATALOG\")\n",
    "EVENTS_VOLUME = dbutils.widgets.get(\"EVENTS_VOLUME\")\n",
    "SIMULATOR_SCHEMA = dbutils.widgets.get(\"SIMULATOR_SCHEMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baaa50c9-8a56-493d-8211-32e6b98da4f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Be cautious about proceeding if the catalog already exists\n",
    "\n",
    "catalogs = [row.catalog for row in spark.sql(\"SHOW CATALOGS\").collect()]\n",
    "if CATALOG in catalogs:\n",
    "    raise Exception(f\"Catalog '{CATALOG}' already exists. Please proceed with caution or choose a different catalog. Use the destroy notebook to clear out previous instances of Casper's.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ad91926-6145-4e86-b9ef-5997be2fc8c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Create main catalog, simulator related schemas and volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bdb0750-5daf-401c-9155-89c4f6a2b65f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"./.state\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4174305-d906-42bc-99d0-79b4e608a613",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG IF NOT EXISTS ${CATALOG};\n",
    "CREATE SCHEMA IF NOT EXISTS ${CATALOG}.${SIMULATOR_SCHEMA};\n",
    "CREATE VOLUME IF NOT EXISTS ${CATALOG}.${SIMULATOR_SCHEMA}.${EVENTS_VOLUME};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db29e236-16c3-499e-aacf-bf4908763242",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Create tables from parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b51d966-932f-4ff8-a159-163f1f2937af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "spark.createDataFrame(pd.read_parquet(\"./data/dimensional/brands.parquet\")) \\\n",
    "    .write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SIMULATOR_SCHEMA}.brands\")\n",
    "spark.createDataFrame(pd.read_parquet(\"./data/dimensional/menus.parquet\")) \\\n",
    "    .write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SIMULATOR_SCHEMA}.menus\")\n",
    "spark.createDataFrame(pd.read_parquet(\"./data/dimensional/categories.parquet\")) \\\n",
    "    .write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SIMULATOR_SCHEMA}.categories\")\n",
    "spark.createDataFrame(pd.read_parquet(\"./data/dimensional/items.parquet\")) \\\n",
    "    .write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SIMULATOR_SCHEMA}.items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8d21c3d-dde3-431b-b615-23ac3ace41f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Start data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cdc9b18-a195-4858-974a-10f7341c3c6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Read all .jsons in ./data/generator/configs. Each json file represents a location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d5fdcf2-1073-4220-80cc-640a0e47e5e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Get all JSON file paths under the directory\n",
    "json_paths = glob.glob(\"data/generator/configs/*.json\")\n",
    "\n",
    "# Read each file's content as a string and collect into a dict mapping filename to content\n",
    "config_json_map = {}\n",
    "for path in json_paths:\n",
    "    filename = os.path.basename(path)\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        config_json_map[filename] = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec8e961b-bac6-43df-8c66-04f7de5d6eb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Start a job for each of the config jsons found in ./data/generator/configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00952076-8f0b-4fe8-a923-0eb7c242103a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "import databricks.sdk.service.jobs as j\n",
    "import os, json\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Resolve the workspace notebook path (keeps your approach)\n",
    "notebook_abs_path = os.path.abspath(\"./data/generator/generator\")\n",
    "notebook_dbx_path = notebook_abs_path.replace(\n",
    "    os.environ.get(\"DATABRICKS_WORKSPACE_ROOT\", \"/Workspace\"),\n",
    "    \"/Workspace\"\n",
    ")\n",
    "\n",
    "state_dir = \"./.state\"\n",
    "os.makedirs(state_dir, exist_ok=True)\n",
    "jobs_file_path = os.path.join(state_dir, \"jobs\")\n",
    "\n",
    "for filename, json_content in config_json_map.items():\n",
    "    job_name = f\"Order Flow Generator: {filename}\"\n",
    "\n",
    "    # Ensure SIM_CFG_JSON is a JSON string (Jobs widget params are strings)\n",
    "    sim_cfg_str = json_content if isinstance(json_content, str) else json.dumps(json_content)\n",
    "\n",
    "    job = w.jobs.create(\n",
    "        name=job_name,\n",
    "        tasks=[\n",
    "            j.Task(\n",
    "                task_key=\"order_flow_generator\",\n",
    "                notebook_task=j.NotebookTask(\n",
    "                    notebook_path=notebook_dbx_path,\n",
    "                    base_parameters={\n",
    "                        \"CATALOG\": CATALOG,\n",
    "                        \"VOLUME\": EVENTS_VOLUME,\n",
    "                        \"SCHEMA\": SIMULATOR_SCHEMA,\n",
    "                        \"SIM_CFG_JSON\": sim_cfg_str,\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    print(f\"Created job_id={job.job_id} for {filename}\")\n",
    "    w.jobs.run_now(job_id=job.job_id)\n",
    "    with open(jobs_file_path, \"a\") as f:\n",
    "        f.write(f\"{job.job_id}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a44d7541-fbf7-4487-9b05-8e25e7dd2050",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Blocking cell to wait for some data to arrive at the volume.\n",
    "\n",
    "The lakeflow declarative pipeline that comes next infers the schema from existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6933ad23-6425-4cac-b23d-049cc0dae38e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Construct the path to the volume where JSONs will arrive\n",
    "volume_path = f\"/Volumes/{CATALOG}/{SIMULATOR_SCHEMA}/{EVENTS_VOLUME}\"\n",
    "\n",
    "def wait_for_data(path, timeout=300, poll_interval=5):\n",
    "    \"\"\"\n",
    "    Wait until at least one file appears in the given path.\n",
    "    Args:\n",
    "        path (str): The directory to watch.\n",
    "        timeout (int): Maximum seconds to wait.\n",
    "        poll_interval (int): Seconds between checks.\n",
    "    Raises:\n",
    "        TimeoutError: If no file appears within the timeout.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    while time.time() - start < timeout:\n",
    "        files = dbutils.fs.ls(path)\n",
    "        if any(f.size > 0 for f in files if not f.path.endswith('/')):\n",
    "            print(\"Data arrived. Safe to proceed.\")\n",
    "            return\n",
    "        time.sleep(poll_interval)\n",
    "    raise TimeoutError(f\"No data found in {path} after {timeout} seconds.\")\n",
    "\n",
    "wait_for_data(volume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5db13125-794c-45ca-93c7-670d9700e8da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Lakeflow Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "239a13b2-8c0b-4460-9d35-c9defae40ea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service import pipelines\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "root_abs_path = os.path.abspath(\"./pipelines/order_items\")\n",
    "root_dbx_path = root_abs_path.replace(\n",
    "    os.environ.get(\"DATABRICKS_WORKSPACE_ROOT\", \"/Workspace\"),\n",
    "    \"/Workspace\"\n",
    ")\n",
    "\n",
    "created = w.pipelines.create(\n",
    "    catalog=CATALOG,\n",
    "    schema='lakeflow',\n",
    "    continuous=True,\n",
    "    name=f\"Order Items Medallion DLT\",\n",
    "    serverless=True,\n",
    "    configuration={\n",
    "        \"RAW_DATA_CATALOG\":CATALOG,\n",
    "        \"RAW_DATA_SCHEMA\":SIMULATOR_SCHEMA,\n",
    "        \"RAW_DATA_VOLUME\":EVENTS_VOLUME\n",
    "    },\n",
    "    root_path=root_dbx_path,\n",
    "    libraries=[pipelines.PipelineLibrary(glob=pipelines.PathPattern(include=f\"{root_dbx_path}/**\"))]\n",
    ")\n",
    "\n",
    "print(f\"Created pipeline_id={created.pipeline_id}\")\n",
    "\n",
    "state_dir = \"./.state\"\n",
    "pipelines_file_path = os.path.join(state_dir, \"pipelines\")\n",
    "with open(pipelines_file_path, \"a\") as f:\n",
    "    f.write(f\"{created.pipeline_id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84e6b7ae-5392-420e-bbfd-90cc4749bcbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8588875451726566,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "init",
   "widgets": {
    "CATALOG": {
     "currentValue": "casperz",
     "nuid": "11cbec7a-980d-492b-af6d-47c909c273ce",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "caspers",
      "label": "",
      "name": "CATALOG",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "caspers",
      "label": "",
      "name": "CATALOG",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "EVENTS_VOLUME": {
     "currentValue": "events",
     "nuid": "98981221-464a-4b5f-a434-6b837733317e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "EVENTS_VOLUME",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "",
      "name": "EVENTS_VOLUME",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "SIMULATOR_SCHEMA": {
     "currentValue": "simulator",
     "nuid": "d2d2354d-0877-4091-a1f4-1ca23c4aacba",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "SIMULATOR_SCHEMA",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "",
      "name": "SIMULATOR_SCHEMA",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
