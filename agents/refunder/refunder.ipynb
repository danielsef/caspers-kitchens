{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ffc7e90-b728-4e83-8cad-3eda46e941e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Tool & View Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a140cb0f-afb5-4c1a-8417-6191aedd8fa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION caspers.ai.get_order_details(oid STRING COMMENT 'order id of the order')\n",
    "RETURNS TABLE (\n",
    "  body STRING COMMENT 'Body of the event',\n",
    "  event_type STRING COMMENT 'The type of event',\n",
    "  order_id STRING COMMENT 'The order id',\n",
    "  ts STRING COMMENT 'The timestamp of the event',\n",
    "  location STRING COMMENT 'the location of the order'\n",
    ")\n",
    "COMMENT 'Returns all events associated with the order id (oid)'\n",
    "RETURN\n",
    "  SELECT body, event_type, order_id, ts, location\n",
    "  FROM caspers.lakeflow.all_events ae\n",
    "  WHERE ae.order_id = oid;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55d1bf76-afca-4d7d-86e3-0b78bdfaf467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION caspers.ai.get_order_delivery_time(oid STRING COMMENT 'order id of the order')\n",
    "RETURNS TABLE (\n",
    "  order_id STRING COMMENT 'The order id',\n",
    "  creation_time TIMESTAMP COMMENT 'The timestamp of the first event for the order',\n",
    "  delivery_time TIMESTAMP COMMENT 'The timestamp of the last event for the order',\n",
    "  duration_minutes FLOAT COMMENT 'The total duration from the first to the last event in minutes'\n",
    ")\n",
    "COMMENT 'Returns the first event time, last event time, and total duration for a given order id.'\n",
    "RETURN\n",
    "  WITH MinMaxTimestamps AS (\n",
    "    SELECT\n",
    "      MIN(try_to_timestamp(ts)) as first_event_time,\n",
    "      MAX(try_to_timestamp(ts)) as last_event_time\n",
    "    FROM\n",
    "      caspers.lakeflow.all_events\n",
    "    WHERE\n",
    "      order_id = oid\n",
    "  )\n",
    "  SELECT\n",
    "    oid as order_id,\n",
    "    first_event_time AS creation_time,\n",
    "    last_event_time AS delivery_time,\n",
    "    CAST(\n",
    "      try_divide(\n",
    "        (UNIX_TIMESTAMP(last_event_time) - UNIX_TIMESTAMP(first_event_time)),\n",
    "        60\n",
    "      ) AS FLOAT\n",
    "    ) AS duration_minutes\n",
    "  FROM\n",
    "    MinMaxTimestamps;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1707682-0913-44bd-b05b-90547ee230fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE VIEW caspers.ai.order_delivery_times_per_location_view AS\n",
    "WITH order_times AS (\n",
    "  SELECT\n",
    "    order_id,\n",
    "    location,\n",
    "    MAX(CASE WHEN event_type = 'order_created' THEN try_to_timestamp(ts) END) AS order_created_time,\n",
    "    MAX(CASE WHEN event_type = 'delivered' THEN try_to_timestamp(ts) END) AS delivered_time\n",
    "  FROM\n",
    "    caspers.lakeflow.all_events\n",
    "  WHERE\n",
    "    try_to_timestamp(ts) >= CURRENT_TIMESTAMP() - INTERVAL 1 DAY\n",
    "  GROUP BY\n",
    "    order_id,\n",
    "    location\n",
    "),\n",
    "total_order_times AS (\n",
    "  SELECT\n",
    "    order_id,\n",
    "    location,\n",
    "    (UNIX_TIMESTAMP(delivered_time) - UNIX_TIMESTAMP(order_created_time)) / 60 AS total_order_time_minutes\n",
    "  FROM\n",
    "    order_times\n",
    "  WHERE\n",
    "    order_created_time IS NOT NULL\n",
    "    AND delivered_time IS NOT NULL\n",
    ")\n",
    "SELECT\n",
    "  location,\n",
    "  PERCENTILE(total_order_time_minutes, 0.50) AS P50,\n",
    "  PERCENTILE(total_order_time_minutes, 0.75) AS P75,\n",
    "  PERCENTILE(total_order_time_minutes, 0.99) AS P99\n",
    "FROM\n",
    "  total_order_times\n",
    "GROUP BY\n",
    "  location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32eca549-67b1-4dc0-9e1a-3e9f131c0e1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION caspers.ai.get_location_timings(loc STRING COMMENT 'Location name as a string')\n",
    "RETURNS TABLE (\n",
    "  location STRING COMMENT 'Location of the order source',\n",
    "  P50 FLOAT COMMENT '50th percentile',\n",
    "  P75 FLOAT COMMENT '75th percentile',\n",
    "  P99 FLOAT COMMENT '99th percentile'\n",
    ")\n",
    "COMMENT 'Returns the 50/75/99th percentile of total delivery times for locations'\n",
    "RETURN\n",
    "  SELECT location, P50, P75, P99\n",
    "  FROM caspers.ai.order_delivery_times_per_location_view AS odlt\n",
    "  WHERE odlt.location = loc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7f5e202-58a3-462e-9f2c-2b61b4366f97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05805ea8-65b7-49c1-90c7-ce255c257ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow-skinny[databricks] langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63ddd9df-5f1c-42ea-9446-196558fd5b2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "from typing import Any, Generator, Optional, Sequence, Union\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    VectorSearchRetrieverTool,\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "system_prompt = \"\"\"You are RefundGPT, a CX agent responsible for refunding late food delivery orders.\n",
    "\n",
    "    You can call tools to gather the information you need. Start with an `order_id`.\n",
    "\n",
    "    Instructions:\n",
    "    1. Call `order_details(order_id)` first to get event history and confirm the id is valid and the order was delivered.\n",
    "    2. Figure out the delivery duration by calling `get_order_delivery_time(order_id)`.\n",
    "    3. Extract the location (either directly or from the first event's body).\n",
    "    4. Call `get_location_timings(location)` to get the P50/P75/P99 values.\n",
    "    5. Compare actual delivery time to those percentiles to decide on a fair refund.\n",
    "\n",
    "    Only provide refunds for late orders, and use only the tool call results to determine whether a refund is appropriate.\n",
    "\n",
    "    Do not provide any refund for orders arriving before the P75 delivery time value.\n",
    "\n",
    "    Output a single-line JSON with these fields:\n",
    "    - `refund_usd` (float),\n",
    "    - `refund_class` (\"none\" | \"partial\" | \"full\"),\n",
    "    - `reason` (short human explanation of whether the order was late and, if late, how late the order was)\n",
    "\n",
    "    You must return only the JSON. No extra text or markdown.\"\"\"\n",
    "\n",
    "###############################################################################\n",
    "## Define tools for your agent, enabling it to retrieve data or take actions\n",
    "## beyond text generation\n",
    "## To create and see usage examples of more tools, see\n",
    "## https://docs.databricks.com/generative-ai/agent-framework/agent-tool.html\n",
    "###############################################################################\n",
    "tools = []\n",
    "\n",
    "uc_tool_names = [\"caspers.ai.get_order_details\", \"caspers.ai.get_location_timings\",\n",
    "                 \"caspers.ai.get_order_delivery_time\"]\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "tools.extend(uc_toolkit.tools)\n",
    "\n",
    "#####################\n",
    "## Define agent logic\n",
    "#####################\n",
    "\n",
    "\n",
    "def create_tool_calling_agent(\n",
    "    model: LanguageModelLike,\n",
    "    tools: Union[Sequence[BaseTool], ToolNode],\n",
    "    system_prompt: Optional[str] = None,\n",
    ") -> CompiledGraph:\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # Define the function that determines which node to go to\n",
    "    def should_continue(state: ChatAgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If there are function calls, continue. else, end\n",
    "        if last_message.get(\"tool_calls\"):\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "            + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    model_runnable = preprocessor | model\n",
    "\n",
    "    def call_model(\n",
    "        state: ChatAgentState,\n",
    "        config: RunnableConfig,\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    workflow.add_node(\"tools\", ChatAgentToolNode(tools))\n",
    "\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"continue\": \"tools\",\n",
    "            \"end\": END,\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        messages = []\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "        return ChatAgentResponse(messages=messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                yield from (\n",
    "                    ChatAgentChunk(**{\"delta\": msg}) for msg in node_data[\"messages\"]\n",
    "                )\n",
    "\n",
    "\n",
    "# Create the agent object, and specify it as the agent object to use when\n",
    "# loading the agent back for inference via mlflow.models.set_model()\n",
    "agent = create_tool_calling_agent(llm, tools, system_prompt)\n",
    "AGENT = LangGraphChatAgent(agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a909c3e-4fd0-4cdd-98af-93a7ccb3badb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# get an actual order_id\n",
    "sample_order_id = spark.sql(\"\"\"\n",
    "    SELECT order_id \n",
    "    FROM caspers.lakeflow.all_events \n",
    "    WHERE event_type='delivered'\n",
    "    LIMIT 1\n",
    "\"\"\").collect()[0]['order_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c672421-c8d0-4252-92d1-576dd01f0f72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert sample_order_id is not None\n",
    "print(sample_order_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38ee737e-0495-4856-a87a-60bac7baf043",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from agent import LLM_ENDPOINT_NAME, tools\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from pkg_resources import get_distribution\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "for tool in tools:\n",
    "    resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{sample_order_id}\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent_v2\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        resources=resources,\n",
    "        pip_requirements=[\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "            f\"mlflow=={get_distribution('mlflow').version}\",\n",
    "            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "mlflow.set_active_model(model_id = logged_agent_info.model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93c5ffb0-ed1b-4e86-809e-9b7af90656e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72348da2-fd71-4413-8e0a-5cb16ed03d17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# sample 10 order_ids\n",
    "refund_queries = [\n",
    "    row['order_id'] for row in spark.sql(\"\"\"\n",
    "        SELECT order_id \n",
    "        FROM caspers.lakeflow.all_events \n",
    "        WHERE event_type='delivered'\n",
    "        LIMIT 10\n",
    "    \"\"\").collect()\n",
    "]\n",
    "\n",
    "# wrap in correct input schema\n",
    "data = []\n",
    "for query in refund_queries:\n",
    "    data.append(\n",
    "        {\n",
    "            \"inputs\": {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": query,\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfcf41db-e682-4ef3-964d-e5c40a07983c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create guideline, run evals\n",
    "\n",
    "from mlflow.genai.scorers import Guidelines\n",
    "import mlflow\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "project_directory = os.path.dirname(notebook_path)\n",
    "\n",
    "# Add the project directory to the system path\n",
    "sys.path.append(project_directory)\n",
    "\n",
    "from agent import AGENT\n",
    "\n",
    "refund_reason = Guidelines(\n",
    "    name=\"refund_reason\",\n",
    "    guidelines=[\"If a refund is offered, its reason must relate to order timing, not to other issues such as missing components.\"]\n",
    ")\n",
    "\n",
    "\n",
    "results = mlflow.genai.evaluate(\n",
    "    data=data,\n",
    "    scorers=[refund_reason],\n",
    "    predict_fn = lambda messages: AGENT.predict({\"messages\": messages})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2f870d6-05d0-478e-8784-98793ba8480c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### log refunder to `UC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "273249df-a966-45fc-9ddf-d7138af804b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "UC_MODEL_NAME = \"caspers.ai.refunder\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf715fb3-953c-4516-8d07-79c0d362a99e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### deploy the agent to model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11c0d2d9-6379-4e2c-84bf-9004dd74b6dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version, scale_to_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "212d8c67-af4d-48c9-88d8-aba01a22edb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7871496513783396,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "refunder",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
